# -*- coding: utf-8 -*-
"""Finding Missing Person using AI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fgugoyxdmpBEu0Vxs5_1D7gMcV8p4zam
"""

# from google.colab import drive
# drive.mount('/content/drive')

!sudo pip install git+https://github.com/rcmalli/keras-vggface.git

pip show keras-vggface

pip install mtcnn

import matplotlib.pyplot as pyplot
# load image from file
pixels = pyplot.imread('/content/Ahmad_Masood_0002.jpg')

from mtcnn.mtcnn import MTCNN
# create the detector, using default weights
detector = MTCNN()
# detect faces in the image
results = detector.detect_faces(pixels)

# example of face detection with mtcnn
from matplotlib import pyplot
from PIL import Image
from numpy import asarray
from mtcnn.mtcnn import MTCNN
 
# extract a single face from a given photograph
def extract_face(filename, required_size=(224, 224)):
	# load image from file
	pixels = pyplot.imread(filename)
	# create the detector, using default weights
	detector = MTCNN()
	# detect faces in the image
	results = detector.detect_faces(pixels)
	# extract the bounding box from the first face
	x1, y1, width, height = results[0]['box']
	x2, y2 = x1 + width, y1 + height
	# extract the face
	face = pixels[y1:y2, x1:x2]
	# resize pixels to the model size
	image = Image.fromarray(face)
	image = image.resize(required_size)
	face_array = asarray(image)
	return face_array
 
# load the photo and extract the face
pixels = extract_face('/content/Ahmad_Masood_0002.jpg')
# plot the extracted face
pyplot.imshow(pixels)
# show the plot
pyplot.show()

!pip install keras_applications

# face verification with the VGGFace2 model
from matplotlib import pyplot
from PIL import Image
from numpy import asarray
from scipy.spatial.distance import cosine
from mtcnn.mtcnn import MTCNN
from keras_vggface.vggface import VGGFace
from keras_vggface.utils import preprocess_input

# VGGFace has an accuracy of 99.13% on the benchmark LFW dataset

# create a vggface model
model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')
''' from keras.models import load_model
model = load_model('/content/drive/MyDrive/Datasets/facefeatures_new_model.h5') '''

# extract faces and calculate face embeddings for a list of photo files
def get_embeddings(filenames):
	# extract faces
	faces = [extract_face(f) for f in filenames]
	# convert into an array of samples
	samples = asarray(faces, 'float32')
	# prepare the face for the model, e.g. center pixels
	samples = preprocess_input(samples, version=2)
	
	# perform prediction
	yhat = model.predict(samples)
	return yhat

# determine if a candidate face is a match for a known face
def is_match(known_embedding, candidate_embedding, thresh=0.5):
	# calculate distance between embeddings
	score = cosine(known_embedding, candidate_embedding)
	if score <= thresh:
		print('>face is a Match (%.3f <= %.3f)' % (score, thresh))
	else:
		print('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))

# define filenames
filenames = ['/content/Ahmad_Masood_0002.jpg','/content/Ahmad_Masood_0002.jpg']
# get embeddings file filenames
embeddings = get_embeddings(filenames)
# define amitabh bachchan
sharon_id = embeddings[0]
# verify known photos of amitabh
print('Positive Tests')
is_match(embeddings[0], embeddings[1])
# is_match(embeddings[0], embeddings[2])
# verify known photos of other people
print('Negative Tests')
# is_match(embeddings[0], embeddings[2])

